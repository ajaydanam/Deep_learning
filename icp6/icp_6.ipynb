{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **QUE 1**"
      ],
      "metadata": {
        "id": "dyF7v54_R1VP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fe7jKJiJARK0",
        "outputId": "ac6ce96b-84cf-4908-f0c2-f9ef71c87319"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Predicting the diabetes disease\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_csv = '/content/gdrive/My Drive/diabetes.csv'"
      ],
      "metadata": {
        "id": "JsT55NFOJqMx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import pandas\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "\n",
        "# load dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "dataset = pd.read_csv(path_to_csv, header=None).values\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(dataset[:,0:8], dataset[:,8],\n",
        "                                                    test_size=0.25, random_state=87)\n",
        "np.random.seed(155)\n",
        "my_first_nn = Sequential() # create model\n",
        "my_first_nn.add(Dense(20, input_dim=8, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(1, activation='sigmoid')) # output layer\n",
        "my_first_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "my_first_nn_fitted = my_first_nn.fit(X_train, Y_train, epochs=100,\n",
        "                                     initial_epoch=0)\n",
        "print(my_first_nn.summary())\n",
        "print(my_first_nn.evaluate(X_test, Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGnqYZ9EJwbY",
        "outputId": "e409a07b-bf29-4226-f8f0-81844932e2b7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "18/18 [==============================] - 1s 3ms/step - loss: 19.0087 - acc: 0.6146\n",
            "Epoch 2/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 13.2255 - acc: 0.5295\n",
            "Epoch 3/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 10.0118 - acc: 0.4931\n",
            "Epoch 4/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 7.0132 - acc: 0.4931\n",
            "Epoch 5/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 4.4223 - acc: 0.4774\n",
            "Epoch 6/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 3.0331 - acc: 0.5243\n",
            "Epoch 7/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 2.5237 - acc: 0.5434\n",
            "Epoch 8/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 2.2901 - acc: 0.5174\n",
            "Epoch 9/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.9465 - acc: 0.5573\n",
            "Epoch 10/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 1.7295 - acc: 0.5625\n",
            "Epoch 11/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 1.5672 - acc: 0.5955\n",
            "Epoch 12/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.4353 - acc: 0.5920\n",
            "Epoch 13/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 1.3230 - acc: 0.6024\n",
            "Epoch 14/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2586 - acc: 0.6059\n",
            "Epoch 15/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 1.1760 - acc: 0.5972\n",
            "Epoch 16/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 1.0860 - acc: 0.6250\n",
            "Epoch 17/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.0401 - acc: 0.6319\n",
            "Epoch 18/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.9819 - acc: 0.6319\n",
            "Epoch 19/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.9622 - acc: 0.6319\n",
            "Epoch 20/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.8955 - acc: 0.6493\n",
            "Epoch 21/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.8689 - acc: 0.6562\n",
            "Epoch 22/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.8221 - acc: 0.6580\n",
            "Epoch 23/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.8503 - acc: 0.6840\n",
            "Epoch 24/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7952 - acc: 0.6840\n",
            "Epoch 25/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7827 - acc: 0.6701\n",
            "Epoch 26/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7574 - acc: 0.6910\n",
            "Epoch 27/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7449 - acc: 0.6684\n",
            "Epoch 28/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7651 - acc: 0.6823\n",
            "Epoch 29/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7403 - acc: 0.6840\n",
            "Epoch 30/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7313 - acc: 0.6806\n",
            "Epoch 31/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7447 - acc: 0.6962\n",
            "Epoch 32/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7417 - acc: 0.6736\n",
            "Epoch 33/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7081 - acc: 0.6840\n",
            "Epoch 34/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6915 - acc: 0.6806\n",
            "Epoch 35/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6945 - acc: 0.6944\n",
            "Epoch 36/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7209 - acc: 0.6875\n",
            "Epoch 37/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6964 - acc: 0.6806\n",
            "Epoch 38/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6446 - acc: 0.6910\n",
            "Epoch 39/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6646 - acc: 0.6944\n",
            "Epoch 40/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6663 - acc: 0.6806\n",
            "Epoch 41/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6802 - acc: 0.6840\n",
            "Epoch 42/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6731 - acc: 0.6927\n",
            "Epoch 43/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6394 - acc: 0.6997\n",
            "Epoch 44/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6259 - acc: 0.6910\n",
            "Epoch 45/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6818 - acc: 0.6788\n",
            "Epoch 46/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6390 - acc: 0.6858\n",
            "Epoch 47/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6186 - acc: 0.6962\n",
            "Epoch 48/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6192 - acc: 0.7014\n",
            "Epoch 49/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6214 - acc: 0.6927\n",
            "Epoch 50/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6186 - acc: 0.7066\n",
            "Epoch 51/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6146 - acc: 0.6997\n",
            "Epoch 52/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6467 - acc: 0.6858\n",
            "Epoch 53/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6454 - acc: 0.7118\n",
            "Epoch 54/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6474 - acc: 0.6753\n",
            "Epoch 55/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6559 - acc: 0.6667\n",
            "Epoch 56/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6584 - acc: 0.6788\n",
            "Epoch 57/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6470 - acc: 0.6806\n",
            "Epoch 58/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6056 - acc: 0.6979\n",
            "Epoch 59/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6047 - acc: 0.6736\n",
            "Epoch 60/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6065 - acc: 0.6875\n",
            "Epoch 61/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6183 - acc: 0.6927\n",
            "Epoch 62/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6189 - acc: 0.6962\n",
            "Epoch 63/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6055 - acc: 0.6875\n",
            "Epoch 64/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6026 - acc: 0.6997\n",
            "Epoch 65/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5928 - acc: 0.6788\n",
            "Epoch 66/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6109 - acc: 0.6927\n",
            "Epoch 67/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6042 - acc: 0.7101\n",
            "Epoch 68/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5988 - acc: 0.7031\n",
            "Epoch 69/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5817 - acc: 0.7118\n",
            "Epoch 70/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6116 - acc: 0.6875\n",
            "Epoch 71/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6056 - acc: 0.7031\n",
            "Epoch 72/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6099 - acc: 0.7170\n",
            "Epoch 73/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6001 - acc: 0.7049\n",
            "Epoch 74/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5872 - acc: 0.6962\n",
            "Epoch 75/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5921 - acc: 0.7188\n",
            "Epoch 76/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6190 - acc: 0.7049\n",
            "Epoch 77/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5922 - acc: 0.7222\n",
            "Epoch 78/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5716 - acc: 0.7083\n",
            "Epoch 79/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5790 - acc: 0.7170\n",
            "Epoch 80/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5878 - acc: 0.6997\n",
            "Epoch 81/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6075 - acc: 0.7066\n",
            "Epoch 82/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6045 - acc: 0.6892\n",
            "Epoch 83/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6018 - acc: 0.6979\n",
            "Epoch 84/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6303 - acc: 0.6944\n",
            "Epoch 85/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5666 - acc: 0.7170\n",
            "Epoch 86/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5856 - acc: 0.7031\n",
            "Epoch 87/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5826 - acc: 0.6962\n",
            "Epoch 88/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6042 - acc: 0.7014\n",
            "Epoch 89/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6064 - acc: 0.7240\n",
            "Epoch 90/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5706 - acc: 0.7066\n",
            "Epoch 91/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5757 - acc: 0.6997\n",
            "Epoch 92/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5724 - acc: 0.7083\n",
            "Epoch 93/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5893 - acc: 0.6927\n",
            "Epoch 94/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6214 - acc: 0.6962\n",
            "Epoch 95/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6095 - acc: 0.6979\n",
            "Epoch 96/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5827 - acc: 0.7031\n",
            "Epoch 97/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5789 - acc: 0.7049\n",
            "Epoch 98/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5679 - acc: 0.7153\n",
            "Epoch 99/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5710 - acc: 0.7101\n",
            "Epoch 100/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6064 - acc: 0.6979\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 20)                180       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 201 (804.00 Byte)\n",
            "Trainable params: 201 (804.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6103 - acc: 0.6927\n",
            "[0.6102634072303772, 0.6927083134651184]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. a. Add more Dense layers to the existing code and check how the accuracy changes."
      ],
      "metadata": {
        "id": "ojWn1rPQSnLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_first_nn = Sequential() # create model\n",
        "my_first_nn.add(Dense(20, input_dim=8, activation='relu')) # hidden layer with input\n",
        "my_first_nn.add(Dense(20, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(20, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(20, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(20, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(20, activation='relu')) # hidden layer\n",
        "\n",
        "my_first_nn.add(Dense(1, activation='sigmoid')) # output layer\n",
        "my_first_nn.compile(loss='binary_crossentropy', optimizer='adam',metrics=['acc']) # compilation\n",
        "my_first_nn_fitted = my_first_nn.fit(X_train, Y_train, epochs=100,verbose=0, initial_epoch=0) # Training\n",
        "print(my_first_nn.summary()) #Summary\n",
        "print(my_first_nn.evaluate(X_test, Y_test)) #Evaluating"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZM8UnDotKttw",
        "outputId": "3eeab27c-7f97-4942-a988-95dec19bdb23"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 20)                180       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 20)                420       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 20)                420       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 20)                420       \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 20)                420       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 20)                420       \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2301 (8.99 KB)\n",
            "Trainable params: 2301 (8.99 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5673 - acc: 0.7552\n",
            "[0.5673202872276306, 0.7552083134651184]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Change the data source to Breast Cancer dataset * available in the source code folder and make required changes. Report accuracy of the model.\n"
      ],
      "metadata": {
        "id": "_mwQy1Y4Tjv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_csv = '/content/gdrive/My Drive/breastcancer.csv'\n",
        "\n",
        "#Importing packages for creating arrays\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#Importing packages to convert Categorical data into Numerical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#Importing packages for splitting data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Importing packages for keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "\n",
        "\n",
        "#Loading the Dataset\n",
        "dataset = pd.read_csv(path_to_csv, header=0)\n",
        "\n"
      ],
      "metadata": {
        "id": "aJpSOVD_S42J"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "HZqm1FU6T2GU",
        "outputId": "6748ab1c-e17a-4e3e-de4e-afd367648d65"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "0      842302         M        17.99         10.38          122.80     1001.0   \n",
              "1      842517         M        20.57         17.77          132.90     1326.0   \n",
              "2    84300903         M        19.69         21.25          130.00     1203.0   \n",
              "3    84348301         M        11.42         20.38           77.58      386.1   \n",
              "4    84358402         M        20.29         14.34          135.10     1297.0   \n",
              "..        ...       ...          ...           ...             ...        ...   \n",
              "564    926424         M        21.56         22.39          142.00     1479.0   \n",
              "565    926682         M        20.13         28.25          131.20     1261.0   \n",
              "566    926954         M        16.60         28.08          108.30      858.1   \n",
              "567    927241         M        20.60         29.33          140.10     1265.0   \n",
              "568     92751         B         7.76         24.54           47.92      181.0   \n",
              "\n",
              "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0            0.11840           0.27760         0.30010              0.14710   \n",
              "1            0.08474           0.07864         0.08690              0.07017   \n",
              "2            0.10960           0.15990         0.19740              0.12790   \n",
              "3            0.14250           0.28390         0.24140              0.10520   \n",
              "4            0.10030           0.13280         0.19800              0.10430   \n",
              "..               ...               ...             ...                  ...   \n",
              "564          0.11100           0.11590         0.24390              0.13890   \n",
              "565          0.09780           0.10340         0.14400              0.09791   \n",
              "566          0.08455           0.10230         0.09251              0.05302   \n",
              "567          0.11780           0.27700         0.35140              0.15200   \n",
              "568          0.05263           0.04362         0.00000              0.00000   \n",
              "\n",
              "     ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
              "0    ...          17.33           184.60      2019.0           0.16220   \n",
              "1    ...          23.41           158.80      1956.0           0.12380   \n",
              "2    ...          25.53           152.50      1709.0           0.14440   \n",
              "3    ...          26.50            98.87       567.7           0.20980   \n",
              "4    ...          16.67           152.20      1575.0           0.13740   \n",
              "..   ...            ...              ...         ...               ...   \n",
              "564  ...          26.40           166.10      2027.0           0.14100   \n",
              "565  ...          38.25           155.00      1731.0           0.11660   \n",
              "566  ...          34.12           126.70      1124.0           0.11390   \n",
              "567  ...          39.42           184.60      1821.0           0.16500   \n",
              "568  ...          30.37            59.16       268.6           0.08996   \n",
              "\n",
              "     compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
              "0              0.66560           0.7119                0.2654          0.4601   \n",
              "1              0.18660           0.2416                0.1860          0.2750   \n",
              "2              0.42450           0.4504                0.2430          0.3613   \n",
              "3              0.86630           0.6869                0.2575          0.6638   \n",
              "4              0.20500           0.4000                0.1625          0.2364   \n",
              "..                 ...              ...                   ...             ...   \n",
              "564            0.21130           0.4107                0.2216          0.2060   \n",
              "565            0.19220           0.3215                0.1628          0.2572   \n",
              "566            0.30940           0.3403                0.1418          0.2218   \n",
              "567            0.86810           0.9387                0.2650          0.4087   \n",
              "568            0.06444           0.0000                0.0000          0.2871   \n",
              "\n",
              "     fractal_dimension_worst  Unnamed: 32  \n",
              "0                    0.11890          NaN  \n",
              "1                    0.08902          NaN  \n",
              "2                    0.08758          NaN  \n",
              "3                    0.17300          NaN  \n",
              "4                    0.07678          NaN  \n",
              "..                       ...          ...  \n",
              "564                  0.07115          NaN  \n",
              "565                  0.06637          NaN  \n",
              "566                  0.07820          NaN  \n",
              "567                  0.12400          NaN  \n",
              "568                  0.07039          NaN  \n",
              "\n",
              "[569 rows x 33 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-91cdc4fe-78cd-495d-ae7d-6aa8925e2b04\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>...</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>...</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>...</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>...</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>926424</td>\n",
              "      <td>M</td>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>...</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>926682</td>\n",
              "      <td>M</td>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>...</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>926954</td>\n",
              "      <td>M</td>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>...</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>927241</td>\n",
              "      <td>M</td>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>...</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>92751</td>\n",
              "      <td>B</td>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows Ã— 33 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-91cdc4fe-78cd-495d-ae7d-6aa8925e2b04')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-91cdc4fe-78cd-495d-ae7d-6aa8925e2b04 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-91cdc4fe-78cd-495d-ae7d-6aa8925e2b04');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-42a707de-e42f-4c1c-bea8-0659039b8387\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-42a707de-e42f-4c1c-bea8-0659039b8387')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-42a707de-e42f-4c1c-bea8-0659039b8387 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#converting Categorical data into Numerical Using Label Encoding\n",
        "le=LabelEncoder()\n",
        "dataset['diagnosis'] = le.fit_transform(dataset['diagnosis'])\n",
        "\n",
        "\n",
        "dataset.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6Lc0Db5T24x",
        "outputId": "b59f6752-61e2-4814-9112-c62c6a1bd73f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 33 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   id                       569 non-null    int64  \n",
            " 1   diagnosis                569 non-null    int64  \n",
            " 2   radius_mean              569 non-null    float64\n",
            " 3   texture_mean             569 non-null    float64\n",
            " 4   perimeter_mean           569 non-null    float64\n",
            " 5   area_mean                569 non-null    float64\n",
            " 6   smoothness_mean          569 non-null    float64\n",
            " 7   compactness_mean         569 non-null    float64\n",
            " 8   concavity_mean           569 non-null    float64\n",
            " 9   concave points_mean      569 non-null    float64\n",
            " 10  symmetry_mean            569 non-null    float64\n",
            " 11  fractal_dimension_mean   569 non-null    float64\n",
            " 12  radius_se                569 non-null    float64\n",
            " 13  texture_se               569 non-null    float64\n",
            " 14  perimeter_se             569 non-null    float64\n",
            " 15  area_se                  569 non-null    float64\n",
            " 16  smoothness_se            569 non-null    float64\n",
            " 17  compactness_se           569 non-null    float64\n",
            " 18  concavity_se             569 non-null    float64\n",
            " 19  concave points_se        569 non-null    float64\n",
            " 20  symmetry_se              569 non-null    float64\n",
            " 21  fractal_dimension_se     569 non-null    float64\n",
            " 22  radius_worst             569 non-null    float64\n",
            " 23  texture_worst            569 non-null    float64\n",
            " 24  perimeter_worst          569 non-null    float64\n",
            " 25  area_worst               569 non-null    float64\n",
            " 26  smoothness_worst         569 non-null    float64\n",
            " 27  compactness_worst        569 non-null    float64\n",
            " 28  concavity_worst          569 non-null    float64\n",
            " 29  concave points_worst     569 non-null    float64\n",
            " 30  symmetry_worst           569 non-null    float64\n",
            " 31  fractal_dimension_worst  569 non-null    float64\n",
            " 32  Unnamed: 32              0 non-null      float64\n",
            "dtypes: float64(31), int64(2)\n",
            "memory usage: 146.8 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting data into Feature Matrix & Label Matrix\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(dataset.iloc[:,2:32], dataset.iloc[:,1], test_size=0.25, random_state=87)\n",
        "\n",
        "\n",
        "my_first_nn = Sequential() # create model\n",
        "my_first_nn.add(Dense(20, input_dim=30, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(20, input_dim=30, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(20, input_dim=30, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(1, activation='sigmoid')) # output layer\n",
        "my_first_nn.compile(loss='binary_crossentropy', optimizer='adam',metrics=['acc']) # compilation\n",
        "my_first_nn_fitted = my_first_nn.fit(X_train, Y_train, epochs=100,verbose=0, initial_epoch=0) # Training\n",
        "print(my_first_nn.summary()) #Summary\n",
        "print(my_first_nn.evaluate(X_test, Y_test)) #Evaluating"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdJkARsQT6nX",
        "outputId": "5616a135-3d24-40bd-d04e-77235f08b986"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_9 (Dense)             (None, 20)                620       \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 20)                420       \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 20)                420       \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1481 (5.79 KB)\n",
            "Trainable params: 1481 (5.79 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4521 - acc: 0.8182\n",
            "[0.45214736461639404, 0.8181818127632141]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Normalize the data before feeding the data to the model and check how the normalization change your accuracy"
      ],
      "metadata": {
        "id": "8ZYhp4IsUV71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing packages for Normalization\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "Lo--42RGUb2g"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_first_nn = Sequential() # create model\n",
        "my_first_nn.add(Dense(20, input_dim=30, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(1, activation='sigmoid')) # output layer\n",
        "my_first_nn.compile(loss='binary_crossentropy', optimizer='adam',metrics=['acc']) # compilation\n",
        "\n",
        "sc = StandardScaler() #Create Model\n",
        "X_train = sc.fit_transform(X_train) #Fit to data, then transform it.\n",
        "X_test = sc.transform(X_test) # Perform standardization by centering and scaling\n",
        "\n",
        "my_first_nn_fitted = my_first_nn.fit(X_train, Y_train, epochs=100,verbose=0, initial_epoch=0) # Training\n",
        "print(my_first_nn.summary()) #Summary\n",
        "print(my_first_nn.evaluate(X_test, Y_test)) #Evaluating"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpEDj3uqUla5",
        "outputId": "de742895-8970-4c8d-dde3-84693a712fe1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_13 (Dense)            (None, 20)                620       \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 641 (2.50 KB)\n",
            "Trainable params: 641 (2.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1143 - acc: 0.9720\n",
            "[0.11434684693813324, 0.9720279574394226]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **QUE 2**"
      ],
      "metadata": {
        "id": "nzYDoCgYUr_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Sequential\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "(train_images,train_labels),(test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "#process the data\n",
        "#1. convert each image of shape 28*28 to 784 dimensional which will be fed to the network as a single feature\n",
        "dimData = np.prod(train_images.shape[1:])\n",
        "print(dimData)\n",
        "train_data = train_images.reshape(train_images.shape[0],dimData)\n",
        "test_data = test_images.reshape(test_images.shape[0],dimData)\n",
        "\n",
        "#convert data to float and scale values between 0 and 1\n",
        "train_data = train_data.astype('float')\n",
        "test_data = test_data.astype('float')\n",
        "#scale data\n",
        "train_data /=255.0\n",
        "test_data /=255.0\n",
        "#change the labels frominteger to one-hot encoding. to_categorical is doing the same thing as LabelEncoder()\n",
        "train_labels_one_hot = to_categorical(train_labels)\n",
        "test_labels_one_hot = to_categorical(test_labels)\n",
        "\n",
        "#creating network\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(dimData,)))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUlTSSPxU1ib",
        "outputId": "b5a17b99-3573-41e0-bb3d-c9aad11364c1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Plot the loss and accuracy for both training data and validation data using the history object in the source code."
      ],
      "metadata": {
        "id": "GYL0GPhSiXgC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_data, train_labels_one_hot, batch_size=256, epochs=10, verbose=1,\n",
        "                   validation_data=(test_data, test_labels_one_hot))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqlKIfDoiTmN",
        "outputId": "50ddd188-da78-4438-cf97-f3951ed38916"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "235/235 [==============================] - 10s 39ms/step - loss: 0.2902 - accuracy: 0.9098 - val_loss: 0.1245 - val_accuracy: 0.9618\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 10s 44ms/step - loss: 0.0992 - accuracy: 0.9692 - val_loss: 0.1077 - val_accuracy: 0.9653\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 8s 32ms/step - loss: 0.0638 - accuracy: 0.9804 - val_loss: 0.0846 - val_accuracy: 0.9735\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 7s 28ms/step - loss: 0.0434 - accuracy: 0.9865 - val_loss: 0.0644 - val_accuracy: 0.9806\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 7s 30ms/step - loss: 0.0316 - accuracy: 0.9899 - val_loss: 0.0711 - val_accuracy: 0.9788\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 7s 29ms/step - loss: 0.0227 - accuracy: 0.9931 - val_loss: 0.0706 - val_accuracy: 0.9813\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 6s 27ms/step - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.1487 - val_accuracy: 0.9607\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.0137 - accuracy: 0.9958 - val_loss: 0.0932 - val_accuracy: 0.9751\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.0109 - accuracy: 0.9965 - val_loss: 0.0757 - val_accuracy: 0.9785\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.0073 - accuracy: 0.9980 - val_loss: 0.0692 - val_accuracy: 0.9838\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[test_loss, test_acc] = model.evaluate(test_data, test_labels_one_hot)\n",
        "print(\"Evaluation result on Test Data : Loss = {}, accuracy = {}\".format(test_loss, test_acc))\n",
        "\n",
        "history.history.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3J1bjN7ivbw",
        "outputId": "b8754c4f-aae9-475e-a898-8b399959b368"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0692 - accuracy: 0.9838\n",
            "Evaluation result on Test Data : Loss = 0.06919123232364655, accuracy = 0.9837999939918518\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['accuracy', 'val_accuracy','loss','val_loss'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "6MX2k-uqi0je",
        "outputId": "3ac3f466-3e64-4f97-cdde-e7caf8e090d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Plot one of the images in the test data, and then do inferencing to check what is the prediction of the model on that single image."
      ],
      "metadata": {
        "id": "ZbigpbRNjUrN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(test_data[0].reshape(28,28))\n",
        "print(\"predicted label:\",model.predict(test_data[0].reshape(1,784)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "OdBq23r4jTti",
        "outputId": "198bc7a9-d049-42a7-b5fc-7d2aee435868"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 231ms/step\n",
            "predicted label: [[0.10515204 0.08642423 0.06644532 0.10861439 0.10271804 0.11496183\n",
            "  0.09834136 0.07863227 0.11081728 0.12789321]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. We had used 2 hidden layers and Relu activation. Try to change the number of hidden layer and the activation to tanh or sigmoid and see what happens."
      ],
      "metadata": {
        "id": "W1Gsxzd4k4oh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#increasing the number of hidden layers to 6\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(dimData,)))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_data, train_labels_one_hot, batch_size=256, epochs=10, verbose=1,\n",
        "                   validation_data=(test_data, test_labels_one_hot))\n",
        "\n",
        "[test_loss1, test_acc1] = model.evaluate(test_data, test_labels_one_hot)\n",
        "print(\"Evaluation result on Test Data with 4 hidden layers: Loss = {}, accuracy = {}\".format(test_loss1, test_acc1))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibm-Jzfck9kH",
        "outputId": "174e42d0-238d-4100-9649-79bb7e15239f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "235/235 [==============================] - 21s 85ms/step - loss: 3.1216 - accuracy: 0.8208 - val_loss: 0.2605 - val_accuracy: 0.9277\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 19s 83ms/step - loss: 0.1847 - accuracy: 0.9500 - val_loss: 0.1559 - val_accuracy: 0.9571\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 24s 100ms/step - loss: 0.1195 - accuracy: 0.9675 - val_loss: 0.1293 - val_accuracy: 0.9653\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 20s 83ms/step - loss: 0.0914 - accuracy: 0.9744 - val_loss: 0.1208 - val_accuracy: 0.9707\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 19s 83ms/step - loss: 0.0774 - accuracy: 0.9804 - val_loss: 0.1786 - val_accuracy: 0.9545\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 21s 90ms/step - loss: 0.0665 - accuracy: 0.9829 - val_loss: 0.1600 - val_accuracy: 0.9689\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 19s 83ms/step - loss: 0.0581 - accuracy: 0.9858 - val_loss: 0.1508 - val_accuracy: 0.9729\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 19s 79ms/step - loss: 0.0525 - accuracy: 0.9875 - val_loss: 0.1780 - val_accuracy: 0.9732\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 19s 83ms/step - loss: 0.0466 - accuracy: 0.9883 - val_loss: 0.1175 - val_accuracy: 0.9782\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 21s 89ms/step - loss: 0.0440 - accuracy: 0.9893 - val_loss: 0.1314 - val_accuracy: 0.9787\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1314 - accuracy: 0.9787\n",
            "Evaluation result on Test Data with 4 hidden layers: Loss = 0.13144926726818085, accuracy = 0.9786999821662903\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#All hidden layers with tanh activation\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='tanh', input_shape=(dimData,)))\n",
        "model.add(Dense(612, activation='tanh'))\n",
        "model.add(Dense(712, activation='tanh'))\n",
        "model.add(Dense(812, activation='tanh'))\n",
        "model.add(Dense(712, activation='tanh'))\n",
        "model.add(Dense(812, activation='tanh'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_data, train_labels_one_hot, batch_size=256, epochs=10, verbose=1,\n",
        "                   validation_data=(test_data, test_labels_one_hot))\n",
        "\n",
        "[test_loss2, test_acc2] = model.evaluate(test_data, test_labels_one_hot)\n",
        "print(\"Evaluation result on Test Data with tanh activation: Loss = {}, accuracy = {}\".format(test_loss2, test_acc3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJ19-ImrlWsL",
        "outputId": "c567faf8-cf2d-421c-b8d7-65d2513968b9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "235/235 [==============================] - 31s 128ms/step - loss: 0.8959 - accuracy: 0.7907 - val_loss: 0.3284 - val_accuracy: 0.9071\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 30s 126ms/step - loss: 0.2958 - accuracy: 0.9122 - val_loss: 0.3440 - val_accuracy: 0.8936\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 30s 129ms/step - loss: 0.2212 - accuracy: 0.9343 - val_loss: 0.2029 - val_accuracy: 0.9406\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 30s 126ms/step - loss: 0.1801 - accuracy: 0.9452 - val_loss: 0.1807 - val_accuracy: 0.9454\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 29s 125ms/step - loss: 0.1542 - accuracy: 0.9531 - val_loss: 0.3942 - val_accuracy: 0.8811\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 29s 126ms/step - loss: 0.1388 - accuracy: 0.9574 - val_loss: 0.4034 - val_accuracy: 0.8879\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 30s 128ms/step - loss: 0.1278 - accuracy: 0.9609 - val_loss: 0.1403 - val_accuracy: 0.9567\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 29s 123ms/step - loss: 0.1156 - accuracy: 0.9641 - val_loss: 0.2009 - val_accuracy: 0.9409\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 33s 142ms/step - loss: 0.1100 - accuracy: 0.9661 - val_loss: 0.1790 - val_accuracy: 0.9466\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 30s 126ms/step - loss: 0.1034 - accuracy: 0.9676 - val_loss: 0.1473 - val_accuracy: 0.9583\n",
            "313/313 [==============================] - 7s 21ms/step - loss: 0.1473 - accuracy: 0.9583\n",
            "Evaluation result on Test Data with tanh activation: Loss = 0.14726443588733673, accuracy = 0.9506000280380249\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Run the same code without scaling the images and check the performance?"
      ],
      "metadata": {
        "id": "V4F9ughOlc3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Sequential\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "(train_images,train_labels),(test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "print(train_images.shape[1:])\n",
        "#process the data\n",
        "#1. convert each image of shape 28*28 to 784 dimensional which will be fed to the network as a single feature\n",
        "dimData = np.prod(train_images.shape[1:])\n",
        "# print(dimData)\n",
        "train_data = train_images.reshape(train_images.shape[0],dimData)\n",
        "test_data = test_images.reshape(test_images.shape[0],dimData)\n",
        "\n",
        "#convert data to float and scale values between 0 and 1\n",
        "train_data = train_data.astype('float')\n",
        "test_data = test_data.astype('float')\n",
        "\n",
        "#change the labels frominteger to one-hot encoding. to_categorical is doing the same thing as LabelEncoder()\n",
        "train_labels_one_hot = to_categorical(train_labels)\n",
        "test_labels_one_hot = to_categorical(test_labels)\n",
        "#creating network\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(dimData,)))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_data, train_labels_one_hot, batch_size=256, epochs=10, verbose=1,\n",
        "                   validation_data=(test_data, test_labels_one_hot))\n",
        "\n",
        "[test_loss3, test_acc3] = model.evaluate(test_data, test_labels_one_hot)\n",
        "print(\"Evaluation result on Test Data without scaling: Loss = {}, accuracy = {}\".format(test_loss3, test_acc3))\n",
        "\n"
      ],
      "metadata": {
        "id": "UTAijGcilqvC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08e62aa6-0fa8-4e02-cba3-41140fb97485"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28, 28)\n",
            "Epoch 1/10\n",
            "235/235 [==============================] - 11s 45ms/step - loss: 8.0447 - accuracy: 0.8668 - val_loss: 0.7363 - val_accuracy: 0.9180\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 8s 32ms/step - loss: 0.4084 - accuracy: 0.9456 - val_loss: 0.3687 - val_accuracy: 0.9439\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 6s 26ms/step - loss: 0.2412 - accuracy: 0.9595 - val_loss: 0.3436 - val_accuracy: 0.9450\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 8s 35ms/step - loss: 0.1952 - accuracy: 0.9671 - val_loss: 0.3727 - val_accuracy: 0.9412\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 6s 26ms/step - loss: 0.1718 - accuracy: 0.9715 - val_loss: 0.2716 - val_accuracy: 0.9586\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 8s 35ms/step - loss: 0.1551 - accuracy: 0.9744 - val_loss: 0.2766 - val_accuracy: 0.9611\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 6s 27ms/step - loss: 0.1363 - accuracy: 0.9781 - val_loss: 0.3401 - val_accuracy: 0.9627\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 8s 35ms/step - loss: 0.1302 - accuracy: 0.9806 - val_loss: 0.4209 - val_accuracy: 0.9618\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 6s 26ms/step - loss: 0.1174 - accuracy: 0.9828 - val_loss: 0.2808 - val_accuracy: 0.9732\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 8s 35ms/step - loss: 0.1151 - accuracy: 0.9841 - val_loss: 0.3383 - val_accuracy: 0.9705\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3383 - accuracy: 0.9705\n",
            "Evaluation result on Test Data without scaling: Loss = 0.3382924199104309, accuracy = 0.9704999923706055\n"
          ]
        }
      ]
    }
  ]
}